{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Is the Relationship between Housing Characteristics and Complaints?\n",
    "\n",
    "The goal of this exercise is to find the answer to the Question 3 of the problem statement: \n",
    "\n",
    "> Does the Complaint Type that you identified in response to Question 1 have an obvious relationship with any particular characteristic or characteristic of the Houses?\n",
    "\n",
    "In this exercise, we shall use the 311 dataset in combination with the PLUTO data set. The latter shall be used for the most problematic borough that was identified as a part of answering the Question 2. \n",
    "Remember that, the answer to Question 1 (What Is the Top Complaint Type?) was: \n",
    "\n",
    "> The most often reported complaint is 'HEAT/HOT WATER'\n",
    "\n",
    "The answe to Question 2 (What Areas Should the Agency Focus On?) was:\n",
    "\n",
    "> The borough with the most 'HEAT/HOT WATER' complaints is 'BRONX'\n",
    "\n",
    "Therefore, in the remainder we shall analyze whether the 'HEAT/HOT WATER' comlaints reported in 'BRONX' have obvious relationship with any particular house characteristics.\n",
    "\n",
    "# The data sets\n",
    "The 311 dataset is already well known to us as it was used to answer Questions 1 & 2, therefore it does not require any special introduction. \n",
    "\n",
    "The PLUTO data set is new to us and it aggregates condominium unit tax lot informationto the billing lot.\n",
    "The initially recommended (by the course advisers) PLUTO data set fields to consider are:\n",
    "\n",
    "|    Field   |                  Description                     |\n",
    "|------------|--------------------------------------------------|\n",
    "| Address    | An address of the tax lot |\n",
    "| BldgArea   | The total gross area in square feet |\n",
    "| BldgDepth  | The buildingâ€™s depth, measured in feet |\n",
    "| BuiltFAR   | The build floor area ration |\n",
    "| CommFAR    | The maximum allowable commercial floor area ratio |\n",
    "| FacilFAR   | The maximum allowable community facility floor area ratio |\n",
    "| Lot        | The one to four-digit tax lot number |\n",
    "| LotArea    | Total area of the tax lot, in square feet |\n",
    "| LotDepth   | The tax lot's depth measured in feet |\n",
    "| NumBldgs   | The number of buildings on the tax lot |\n",
    "| NumFloors  | The number of full and partialstories starting from the ground floor, for the tallest building on the tax lot |\n",
    "| OfficeArea | An estimate of theexterior dimensions of the portion of the structure(s) allocated for office use |\n",
    "| ResArea    | An estimate of the exterior dimensions of the portion of the structure(s) allocated for residential use |\n",
    "| ResidFAR   | The maximum allowable residential floor area ratio |\n",
    "| RetailArea | An estimate of the exterior dimensions of the portion of the structure(s) allocated for retail use |\n",
    "| YearBuilt  | The year construction of the building was completed |\n",
    "| YearAlter1 | Is the year of the building's most recent alteration |\n",
    "| ZipCode    | A ZIP code that is valid for one of the addresses assigned to the tax lot |\n",
    "| XCoord     | The X coordinate of the XY coordinate pair which depicts the approximate location of the lot |\n",
    "| YCoord     | The Y coordinate of the XY coordinate pair which depicts the approximate location of the lot |\n",
    "\n",
    "Consider reading the [PLUTO Data Dictionary](https://www1.nyc.gov/assets/planning/download/pdf/data-maps/open-data/pluto_datadictionary.pdf?r=19v2) for more details. The data set archive consists of several CSV files, each devoted to a single borough:\n",
    "\n",
    "|   CSV file  |      Borough       |\n",
    "|-------------|--------------------|\n",
    "| QN_18v1.csv | QUEENS |\n",
    "| BK_18v1.csv | BROOKLYN |\n",
    "| SI_18v1.csv | STATEN ISLAND |\n",
    "| BX_18v1.csv | BRONX |\n",
    "| MN_18v1.csv | MANHATTAN |\n",
    "\n",
    "Since we are interested in borough *'BRONX'* we shall use the data from the corresponding *'BX_18v1.csv'* file.\n",
    "\n",
    "\n",
    "# Load the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading of the data can be done both from the IBM cloud storage and the locally present CSV files. The latter is decided upon the presence of the proper secure field values of the credentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ibm_boto3\n",
    "\n",
    "from botocore.client import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "SECURITY_DUMMY = '----------------'\n",
    "erm2_nwe9_creds = {\n",
    "    'IAM_SERVICE_ID'    : SECURITY_DUMMY,\n",
    "    'IBM_API_KEY_ID'    : SECURITY_DUMMY,\n",
    "    'ENDPOINT'          : 'https://s3.eu-geo.objectstorage.service.networklayer.com',\n",
    "    'IBM_AUTH_ENDPOINT' : 'https://iam.eu-gb.bluemix.net/oidc/token',\n",
    "    'BUCKET'            : SECURITY_DUMMY,\n",
    "    'FILE'              : 'erm2_nwe9.csv'\n",
    "}\n",
    "bx_18v1_creds = {\n",
    "    'IAM_SERVICE_ID'    : SECURITY_DUMMY,\n",
    "    'IBM_API_KEY_ID'    : SECURITY_DUMMY,\n",
    "    'ENDPOINT'          : 'https://s3.eu-geo.objectstorage.service.networklayer.com',\n",
    "    'IBM_AUTH_ENDPOINT' : 'https://iam.eu-gb.bluemix.net/oidc/token',\n",
    "    'BUCKET'            : SECURITY_DUMMY,\n",
    "    'FILE'              : 'BX_18v1.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows to get the data source for the credentials from the IBM cloud or local csv file \n",
    "def get_data_source(credentials) :\n",
    "    '''Creates a data source from the IBM cloud or local csv file according to the credentials'''\n",
    "    # Here we check if the credentials are present, if not try \n",
    "    # load the local file if they are then read from the cloud.\n",
    "    if credentials.get('IAM_SERVICE_ID') == SECURITY_DUMMY :\n",
    "        # This is the alternative to get the code run locally with a local csv file\n",
    "        body = 'data' + os.path.sep + credentials.get('FILE')\n",
    "    else :\n",
    "        client = ibm_boto3.client(\n",
    "            service_name = 's3',\n",
    "            ibm_api_key_id = credentials.get('IBM_API_KEY_ID'),\n",
    "            ibm_auth_endpoint = credentials.get('IBM_AUTH_ENDPOINT'),\n",
    "            config = Config(signature_version='oauth'),\n",
    "            endpoint_url = credentials.get('ENDPOINT'))\n",
    "\n",
    "        body = client.get_object(\n",
    "            Bucket = credentials.get('BUCKET'),\n",
    "            Key = credentials.get('FILE'))['Body']\n",
    "\n",
    "        # add missing __iter__ method, so pandas accepts body as file-like object\n",
    "        def __iter__(self): return 0\n",
    "        if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "    return body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, we shall subsequently load the 311 and PLUTO data sets. Along the way, we will select the necessary columns and check on (, and correct if needed,) the column data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The 311 data set\n",
    "Here we first load the 311 data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data source for the credentials\n",
    "dhp_ds = get_data_source(erm2_nwe9_creds)\n",
    "\n",
    "# Read the CSV file\n",
    "dhp_df = pd.read_csv(dhp_ds, parse_dates = ['created_date', 'closed_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we select the data related to the 'HEAT/HOT WATER' comlaints reported in 'BRONX'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all complaints: 6034470\n",
      "Number of 'HEAT/HOT WATER' complaints in 'BRONX': 609783\n"
     ]
    }
   ],
   "source": [
    "print('Number of all complaints:', dhp_df.shape[0])\n",
    "dhp_df = dhp_df[(dhp_df['complaint_type'] == 'HEAT/HOT WATER') & (dhp_df['borough'] == 'BRONX')]\n",
    "print('Number of \\'HEAT/HOT WATER\\' complaints in \\'BRONX\\':', dhp_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next lest us realize that the 311 data set will only be user to select the lots from the PLUTO data set which had 'HEAT/HOT WATER' complaints in 'BRONX'. Therefore, we shall only keep the relevant columns here, i.e. the property zip code and address. We shall also rename the columns to match those of PLUTO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>ZipCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>511 EAST  148 STREET</td>\n",
       "      <td>10455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1275 EDWARD L GRANT HIGHWAY</td>\n",
       "      <td>10452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>152 EAST  171 STREET</td>\n",
       "      <td>10452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2523 UNIVERSITY AVENUE</td>\n",
       "      <td>10468.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3226 BRONXWOOD AVENUE</td>\n",
       "      <td>10469.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Address  ZipCode\n",
       "0          511 EAST  148 STREET  10455.0\n",
       "7   1275 EDWARD L GRANT HIGHWAY  10452.0\n",
       "12         152 EAST  171 STREET  10452.0\n",
       "16       2523 UNIVERSITY AVENUE  10468.0\n",
       "26        3226 BRONXWOOD AVENUE  10469.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhp_df = dhp_df[['incident_address', 'incident_zip']]\n",
    "dhp_df = dhp_df.rename({'incident_address':'Address', 'incident_zip':'ZipCode'}, axis=1)\n",
    "dhp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let us check on the column types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address     object\n",
       "ZipCode    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhp_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The types are in order as the address is a string and the zip code is a float.\n",
    "\n",
    "## The PLUTO data set\n",
    "Here we first load the PLUTO data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data source for the credentials\n",
    "bx_ds = get_data_source(bx_18v1_creds)\n",
    "\n",
    "# Read the CSV file\n",
    "bx_df = pd.read_csv(bx_ds, low_memory = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we select the recommended fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx_df = bx_df[['Address', 'BldgArea', 'BldgDepth', 'BuiltFAR',\n",
    "              'CommFAR', 'FacilFAR', 'Lot', 'LotArea', 'LotDepth',\n",
    "              'NumBldgs', 'NumFloors', 'OfficeArea', 'ResArea',\n",
    "              'ResidFAR', 'RetailArea', 'YearBuilt', 'YearAlter1',\n",
    "              'ZipCode', 'YCoord', 'XCoord']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further list the types of the columns to check if they are all in order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address        object\n",
       "BldgArea        int64\n",
       "BldgDepth     float64\n",
       "BuiltFAR      float64\n",
       "CommFAR       float64\n",
       "FacilFAR      float64\n",
       "Lot             int64\n",
       "LotArea         int64\n",
       "LotDepth      float64\n",
       "NumBldgs        int64\n",
       "NumFloors     float64\n",
       "OfficeArea      int64\n",
       "ResArea         int64\n",
       "ResidFAR      float64\n",
       "RetailArea      int64\n",
       "YearBuilt       int64\n",
       "YearAlter1      int64\n",
       "ZipCode       float64\n",
       "YCoord        float64\n",
       "XCoord        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data frame columns have proper numeric types, except for the Address one which is a string.\n",
    "\n",
    "# Data Exploration and Cleaning\n",
    "In this section we shall do the initial data exploration of the 311 and PLUTO data sets. As a part of this exploration we will do data cleaning in order to prepare the data sets to subsequent analysis.\n",
    "\n",
    "## The 311 data set\n",
    "\n",
    "We can now describe the 311 data set to get some insights in the remaining data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>ZipCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>609782</td>\n",
       "      <td>603797.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>22902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>3810 BAILEY AVENUE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>7115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10460.695938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.493728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10451.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10456.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10467.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10803.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Address        ZipCode\n",
       "count               609782  603797.000000\n",
       "unique               22902            NaN\n",
       "top     3810 BAILEY AVENUE            NaN\n",
       "freq                  7115            NaN\n",
       "mean                   NaN   10460.695938\n",
       "std                    NaN       6.493728\n",
       "min                    NaN   10451.000000\n",
       "25%                    NaN   10456.000000\n",
       "50%                    NaN   10460.000000\n",
       "75%                    NaN   10467.000000\n",
       "max                    NaN   10803.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhp_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no much to see here as the provided statistics is mostly not informative. For the address, we can only tell that there are `609782` non Na/NaN  ones among which `22902` are unique and that the top complaints address is `3810 BAILEY AVENUE` with `7115` comlaints over all the years. For the zip codes the amount of useful information is even less, we can just use the number of non Na/NaN zip codes: `603797`. The latter indicates that there are about `609782 - 603797 = 5985` Na/NaN zip codes. Thereore, let us now explicitly check for the present Na/NaN values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing addresses is: 1 \n",
      "The number of missing zip codes is: 5986\n"
     ]
    }
   ],
   "source": [
    "missing = dhp_df.isna()\n",
    "print('The number of missing addresses is:', missing.Address.sum(),\n",
    "      '\\nThe number of missing zip codes is:', missing.ZipCode.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see there are missing values which we can not easily restore, so let us drop the corresponding rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of complaints including Na/NaN values: 609783\n",
      "The number of clean complaints: 603797\n"
     ]
    }
   ],
   "source": [
    "print('The number of complaints including Na/NaN values:', dhp_df.shape[0])\n",
    "dhp_df.dropna(inplace = True)\n",
    "print('The number of clean complaints:', dhp_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see, the amount of dropped data is marginal, i.e. it just about `100 - (603797 * 100 /609783) =  0.98`%.\n",
    "\n",
    "## The PLUTO data set\n",
    "We can now describe the PLUTO data set to get some insights in the selected data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>BldgArea</th>\n",
       "      <th>BldgDepth</th>\n",
       "      <th>BuiltFAR</th>\n",
       "      <th>CommFAR</th>\n",
       "      <th>FacilFAR</th>\n",
       "      <th>Lot</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>LotDepth</th>\n",
       "      <th>NumBldgs</th>\n",
       "      <th>NumFloors</th>\n",
       "      <th>OfficeArea</th>\n",
       "      <th>ResArea</th>\n",
       "      <th>ResidFAR</th>\n",
       "      <th>RetailArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearAlter1</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>YCoord</th>\n",
       "      <th>XCoord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>86591</td>\n",
       "      <td>8.659100e+04</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>8.659100e+04</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>8.659100e+04</td>\n",
       "      <td>8.659100e+04</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>8.659100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>85962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>WEST 246 STREET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.341031e+03</td>\n",
       "      <td>49.855709</td>\n",
       "      <td>1.143734</td>\n",
       "      <td>0.123250</td>\n",
       "      <td>2.870513</td>\n",
       "      <td>105.260893</td>\n",
       "      <td>9.479385e+03</td>\n",
       "      <td>104.972907</td>\n",
       "      <td>1.224896</td>\n",
       "      <td>2.350154</td>\n",
       "      <td>5.227774e+02</td>\n",
       "      <td>5.891092e+03</td>\n",
       "      <td>1.690055</td>\n",
       "      <td>362.536234</td>\n",
       "      <td>1865.568177</td>\n",
       "      <td>182.272673</td>\n",
       "      <td>10464.266333</td>\n",
       "      <td>249976.088242</td>\n",
       "      <td>1.021686e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.625799e+04</td>\n",
       "      <td>30.325272</td>\n",
       "      <td>1.810324</td>\n",
       "      <td>0.561512</td>\n",
       "      <td>1.597633</td>\n",
       "      <td>426.684680</td>\n",
       "      <td>2.992482e+05</td>\n",
       "      <td>63.283144</td>\n",
       "      <td>1.947582</td>\n",
       "      <td>1.441622</td>\n",
       "      <td>1.218634e+04</td>\n",
       "      <td>5.752111e+04</td>\n",
       "      <td>1.304745</td>\n",
       "      <td>5001.922740</td>\n",
       "      <td>382.054716</td>\n",
       "      <td>575.285484</td>\n",
       "      <td>6.642540</td>\n",
       "      <td>9778.381084</td>\n",
       "      <td>8.598740e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10451.000000</td>\n",
       "      <td>227527.000000</td>\n",
       "      <td>1.002677e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.665000e+03</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.200000e+03</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.215000e+03</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10460.000000</td>\n",
       "      <td>241918.000000</td>\n",
       "      <td>1.014311e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.280000e+03</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>2.512000e+03</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.816000e+03</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1931.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10465.000000</td>\n",
       "      <td>248586.000000</td>\n",
       "      <td>1.023321e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.321000e+03</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>4.200000e+03</td>\n",
       "      <td>102.070000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.650000e+03</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1960.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10469.000000</td>\n",
       "      <td>258037.000000</td>\n",
       "      <td>1.027126e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.354011e+07</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>259.800000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7505.000000</td>\n",
       "      <td>7.425000e+07</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.311800e+06</td>\n",
       "      <td>1.321140e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>598908.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>11370.000000</td>\n",
       "      <td>272275.000000</td>\n",
       "      <td>1.047777e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Address      BldgArea     BldgDepth      BuiltFAR  \\\n",
       "count             86591  8.659100e+04  86591.000000  86591.000000   \n",
       "unique            85962           NaN           NaN           NaN   \n",
       "top     WEST 246 STREET           NaN           NaN           NaN   \n",
       "freq                 23           NaN           NaN           NaN   \n",
       "mean                NaN  8.341031e+03     49.855709      1.143734   \n",
       "std                 NaN  6.625799e+04     30.325272      1.810324   \n",
       "min                 NaN  0.000000e+00      0.000000      0.000000   \n",
       "25%                 NaN  1.665000e+03     35.000000      0.590000   \n",
       "50%                 NaN  2.280000e+03     45.000000      0.880000   \n",
       "75%                 NaN  3.321000e+03     56.000000      1.270000   \n",
       "max                 NaN  1.354011e+07   1300.000000    259.800000   \n",
       "\n",
       "             CommFAR      FacilFAR           Lot       LotArea      LotDepth  \\\n",
       "count   86591.000000  86591.000000  86591.000000  8.659100e+04  86591.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        0.123250      2.870513    105.260893  9.479385e+03    104.972907   \n",
       "std         0.561512      1.597633    426.684680  2.992482e+05     63.283144   \n",
       "min         0.000000      0.000000      1.000000  0.000000e+00      0.000000   \n",
       "25%         0.000000      2.000000     20.000000  2.200000e+03     95.000000   \n",
       "50%         0.000000      2.000000     41.000000  2.512000e+03    100.000000   \n",
       "75%         0.000000      4.800000     72.000000  4.200000e+03    102.070000   \n",
       "max         9.000000     10.000000   7505.000000  7.425000e+07   8000.000000   \n",
       "\n",
       "            NumBldgs     NumFloors    OfficeArea       ResArea      ResidFAR  \\\n",
       "count   86591.000000  86591.000000  8.659100e+04  8.659100e+04  86591.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        1.224896      2.350154  5.227774e+02  5.891092e+03      1.690055   \n",
       "std         1.947582      1.441622  1.218634e+04  5.752111e+04      1.304745   \n",
       "min         0.000000      0.000000  0.000000e+00  0.000000e+00      0.000000   \n",
       "25%         1.000000      2.000000  0.000000e+00  1.215000e+03      0.900000   \n",
       "50%         1.000000      2.000000  0.000000e+00  1.816000e+03      1.100000   \n",
       "75%         1.000000      3.000000  0.000000e+00  2.650000e+03      2.430000   \n",
       "max       251.000000     44.000000  1.311800e+06  1.321140e+07     10.000000   \n",
       "\n",
       "           RetailArea     YearBuilt    YearAlter1       ZipCode  \\\n",
       "count    86591.000000  86591.000000  86591.000000  86591.000000   \n",
       "unique            NaN           NaN           NaN           NaN   \n",
       "top               NaN           NaN           NaN           NaN   \n",
       "freq              NaN           NaN           NaN           NaN   \n",
       "mean       362.536234   1865.568177    182.272673  10464.266333   \n",
       "std       5001.922740    382.054716    575.285484      6.642540   \n",
       "min          0.000000      0.000000      0.000000  10451.000000   \n",
       "25%          0.000000   1920.000000      0.000000  10460.000000   \n",
       "50%          0.000000   1931.000000      0.000000  10465.000000   \n",
       "75%          0.000000   1960.000000      0.000000  10469.000000   \n",
       "max     598908.000000   2017.000000   2017.000000  11370.000000   \n",
       "\n",
       "               YCoord        XCoord  \n",
       "count    86591.000000  8.659100e+04  \n",
       "unique            NaN           NaN  \n",
       "top               NaN           NaN  \n",
       "freq              NaN           NaN  \n",
       "mean    249976.088242  1.021686e+06  \n",
       "std       9778.381084  8.598740e+03  \n",
       "min     227527.000000  1.002677e+06  \n",
       "25%     241918.000000  1.014311e+06  \n",
       "50%     248586.000000  1.023321e+06  \n",
       "75%     258037.000000  1.027126e+06  \n",
       "max     272275.000000  1.047777e+06  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bx_desc = bx_df.describe(include='all')\n",
    "display(bx_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a look at the counts row we can see that the numbers varry:\n",
    "* *'Address'* has `89785`\n",
    "* *'BldgArea'* to *'YearAlter1'* have `89854`\n",
    "* *'ZipCode'* has `89525`\n",
    "* *'YCoord'* and *'XCoord'* have `86595`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address       89785\n",
       "BldgArea      89854\n",
       "BldgDepth     89854\n",
       "BuiltFAR      89854\n",
       "CommFAR       89854\n",
       "FacilFAR      89854\n",
       "Lot           89854\n",
       "LotArea       89854\n",
       "LotDepth      89854\n",
       "NumBldgs      89854\n",
       "NumFloors     89854\n",
       "OfficeArea    89854\n",
       "ResArea       89854\n",
       "ResidFAR      89854\n",
       "RetailArea    89854\n",
       "YearBuilt     89854\n",
       "YearAlter1    89854\n",
       "ZipCode       89525\n",
       "YCoord        86595\n",
       "XCoord        86595\n",
       "Name: count, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx_df.describe(include='all').loc['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of rows in the data set is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tax lots: 86591\n"
     ]
    }
   ],
   "source": [
    "print('The number of tax lots:', bx_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let us analyze the number of the Na/NaN values, only display columns with positive Na/NaN counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address      69\n",
       "ZipCode     329\n",
       "YCoord     3259\n",
       "XCoord     3259\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of Na/NaN values is 6916\n"
     ]
    }
   ],
   "source": [
    "missing_counts = bx_df.isna().apply(sum, axis = 0)\n",
    "display(missing_counts[missing_counts > 0])\n",
    "print('The total number of Na/NaN values is', np.sum(missing_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Assuming the missing values can not be easily restored let us remove the corresponding rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The remaining number of rows with Na/NaN values is 0\n",
      "The remaining number of rows in PLUTO is 86591\n"
     ]
    }
   ],
   "source": [
    "bx_df.dropna(inplace = True)\n",
    "missing_counts = bx_df.isna().apply(sum, axis = 0)\n",
    "print('The remaining number of rows with Na/NaN values is', np.sum(missing_counts))\n",
    "print('The remaining number of rows in PLUTO is', bx_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see, the amount of dropped data is sufficiently small, i.e. it just about `100 - (86591 * 100 /89854) =  3.63`%. Let us now describe the data set again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>BldgArea</th>\n",
       "      <th>BldgDepth</th>\n",
       "      <th>BuiltFAR</th>\n",
       "      <th>CommFAR</th>\n",
       "      <th>FacilFAR</th>\n",
       "      <th>Lot</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>LotDepth</th>\n",
       "      <th>NumBldgs</th>\n",
       "      <th>NumFloors</th>\n",
       "      <th>OfficeArea</th>\n",
       "      <th>ResArea</th>\n",
       "      <th>ResidFAR</th>\n",
       "      <th>RetailArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearAlter1</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>YCoord</th>\n",
       "      <th>XCoord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>86591</td>\n",
       "      <td>8.659100e+04</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>8.659100e+04</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>8.659100e+04</td>\n",
       "      <td>8.659100e+04</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>86591.000000</td>\n",
       "      <td>8.659100e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>85962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>WEST 246 STREET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.341031e+03</td>\n",
       "      <td>49.855709</td>\n",
       "      <td>1.143734</td>\n",
       "      <td>0.123250</td>\n",
       "      <td>2.870513</td>\n",
       "      <td>105.260893</td>\n",
       "      <td>9.479385e+03</td>\n",
       "      <td>104.972907</td>\n",
       "      <td>1.224896</td>\n",
       "      <td>2.350154</td>\n",
       "      <td>5.227774e+02</td>\n",
       "      <td>5.891092e+03</td>\n",
       "      <td>1.690055</td>\n",
       "      <td>362.536234</td>\n",
       "      <td>1865.568177</td>\n",
       "      <td>182.272673</td>\n",
       "      <td>10464.266333</td>\n",
       "      <td>249976.088242</td>\n",
       "      <td>1.021686e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.625799e+04</td>\n",
       "      <td>30.325272</td>\n",
       "      <td>1.810324</td>\n",
       "      <td>0.561512</td>\n",
       "      <td>1.597633</td>\n",
       "      <td>426.684680</td>\n",
       "      <td>2.992482e+05</td>\n",
       "      <td>63.283144</td>\n",
       "      <td>1.947582</td>\n",
       "      <td>1.441622</td>\n",
       "      <td>1.218634e+04</td>\n",
       "      <td>5.752111e+04</td>\n",
       "      <td>1.304745</td>\n",
       "      <td>5001.922740</td>\n",
       "      <td>382.054716</td>\n",
       "      <td>575.285484</td>\n",
       "      <td>6.642540</td>\n",
       "      <td>9778.381084</td>\n",
       "      <td>8.598740e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10451.000000</td>\n",
       "      <td>227527.000000</td>\n",
       "      <td>1.002677e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.665000e+03</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.200000e+03</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.215000e+03</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10460.000000</td>\n",
       "      <td>241918.000000</td>\n",
       "      <td>1.014311e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.280000e+03</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>2.512000e+03</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.816000e+03</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1931.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10465.000000</td>\n",
       "      <td>248586.000000</td>\n",
       "      <td>1.023321e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.321000e+03</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>4.200000e+03</td>\n",
       "      <td>102.070000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.650000e+03</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1960.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10469.000000</td>\n",
       "      <td>258037.000000</td>\n",
       "      <td>1.027126e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.354011e+07</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>259.800000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7505.000000</td>\n",
       "      <td>7.425000e+07</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.311800e+06</td>\n",
       "      <td>1.321140e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>598908.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>11370.000000</td>\n",
       "      <td>272275.000000</td>\n",
       "      <td>1.047777e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Address      BldgArea     BldgDepth      BuiltFAR  \\\n",
       "count             86591  8.659100e+04  86591.000000  86591.000000   \n",
       "unique            85962           NaN           NaN           NaN   \n",
       "top     WEST 246 STREET           NaN           NaN           NaN   \n",
       "freq                 23           NaN           NaN           NaN   \n",
       "mean                NaN  8.341031e+03     49.855709      1.143734   \n",
       "std                 NaN  6.625799e+04     30.325272      1.810324   \n",
       "min                 NaN  0.000000e+00      0.000000      0.000000   \n",
       "25%                 NaN  1.665000e+03     35.000000      0.590000   \n",
       "50%                 NaN  2.280000e+03     45.000000      0.880000   \n",
       "75%                 NaN  3.321000e+03     56.000000      1.270000   \n",
       "max                 NaN  1.354011e+07   1300.000000    259.800000   \n",
       "\n",
       "             CommFAR      FacilFAR           Lot       LotArea      LotDepth  \\\n",
       "count   86591.000000  86591.000000  86591.000000  8.659100e+04  86591.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        0.123250      2.870513    105.260893  9.479385e+03    104.972907   \n",
       "std         0.561512      1.597633    426.684680  2.992482e+05     63.283144   \n",
       "min         0.000000      0.000000      1.000000  0.000000e+00      0.000000   \n",
       "25%         0.000000      2.000000     20.000000  2.200000e+03     95.000000   \n",
       "50%         0.000000      2.000000     41.000000  2.512000e+03    100.000000   \n",
       "75%         0.000000      4.800000     72.000000  4.200000e+03    102.070000   \n",
       "max         9.000000     10.000000   7505.000000  7.425000e+07   8000.000000   \n",
       "\n",
       "            NumBldgs     NumFloors    OfficeArea       ResArea      ResidFAR  \\\n",
       "count   86591.000000  86591.000000  8.659100e+04  8.659100e+04  86591.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        1.224896      2.350154  5.227774e+02  5.891092e+03      1.690055   \n",
       "std         1.947582      1.441622  1.218634e+04  5.752111e+04      1.304745   \n",
       "min         0.000000      0.000000  0.000000e+00  0.000000e+00      0.000000   \n",
       "25%         1.000000      2.000000  0.000000e+00  1.215000e+03      0.900000   \n",
       "50%         1.000000      2.000000  0.000000e+00  1.816000e+03      1.100000   \n",
       "75%         1.000000      3.000000  0.000000e+00  2.650000e+03      2.430000   \n",
       "max       251.000000     44.000000  1.311800e+06  1.321140e+07     10.000000   \n",
       "\n",
       "           RetailArea     YearBuilt    YearAlter1       ZipCode  \\\n",
       "count    86591.000000  86591.000000  86591.000000  86591.000000   \n",
       "unique            NaN           NaN           NaN           NaN   \n",
       "top               NaN           NaN           NaN           NaN   \n",
       "freq              NaN           NaN           NaN           NaN   \n",
       "mean       362.536234   1865.568177    182.272673  10464.266333   \n",
       "std       5001.922740    382.054716    575.285484      6.642540   \n",
       "min          0.000000      0.000000      0.000000  10451.000000   \n",
       "25%          0.000000   1920.000000      0.000000  10460.000000   \n",
       "50%          0.000000   1931.000000      0.000000  10465.000000   \n",
       "75%          0.000000   1960.000000      0.000000  10469.000000   \n",
       "max     598908.000000   2017.000000   2017.000000  11370.000000   \n",
       "\n",
       "               YCoord        XCoord  \n",
       "count    86591.000000  8.659100e+04  \n",
       "unique            NaN           NaN  \n",
       "top               NaN           NaN  \n",
       "freq              NaN           NaN  \n",
       "mean    249976.088242  1.021686e+06  \n",
       "std       9778.381084  8.598740e+03  \n",
       "min     227527.000000  1.002677e+06  \n",
       "25%     241918.000000  1.014311e+06  \n",
       "50%     248586.000000  1.023321e+06  \n",
       "75%     258037.000000  1.027126e+06  \n",
       "max     272275.000000  1.047777e+06  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is now one other thing to notice, namely:\n",
    "\n",
    "> The 'WEST 246 STREET' Address frequency within the PLUTO data set is indicated to be 23 \n",
    "\n",
    "If we now list all the addresses with their larger than 1 frequencies, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WEST 246 STREET        23\n",
       "SHORE DRIVE            20\n",
       "595 WEST 239 STREET    13\n",
       "SEDGWICK AVENUE        12\n",
       "CORNELL AVENUE         11\n",
       "                       ..\n",
       "4487 3 AVENUE           2\n",
       "1023 KELLY STREET       2\n",
       "1727 HAIGHT AVENUE      2\n",
       "SEYMOUR AVENUE          2\n",
       "158 HAWKINS STREET      2\n",
       "Name: Address, Length: 277, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address_cnts = bx_df.Address.value_counts()\n",
    "address_cnts[address_cnts > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which consists of 227 addresses and some of them, e.g. the 'SHORE DRIVE' do not have house numbers. This seems confusing as we would expect the address to start with the house number and then to be followed by the street name. Moreover, for the tax lots we would expect to see a single address present in the data set only once.\n",
    "\n",
    "Let us now read-up on the PLUTO data set description of the *'Address'* column:\n",
    "\n",
    "> Tax lots may be assigned a single house number on a street, a range of house numbers on a street, or addresses on multiple streets. ADDRESS contains the address in PTS, using the low number when there is a range of house numbers. Some tax lots, such as vacant lots or parks, have only a street name and no house number.\n",
    "\n",
    "> A complete list of the addresses assigned to a tax lot is available through Geosupport or by downloading the Property Address Directory(PAD) BYTESof the BIGAPPLETM. \n",
    "\n",
    "As one can read from the quotes above:\n",
    "\n",
    "1. The vacant lots and or parks do not have house numbers assigned.\n",
    "2. The address contains the low number when there is a range of house numbers.\n",
    "3. The lot can also be assigned to addresses on multiple streets.\n",
    "\n",
    "These facts will thremendously complicate the analysis because:\n",
    "\n",
    "* Bullets 1 and 2 mean that, without using an additional PAD data set we can not get the complete list of the lot house numbers. This shall result in some 311 complaints not being able to match with a tax lot.\n",
    "* Bullet 3 means that it is perhaps possible that there are addresses containing lists of house and street numbers. Those whill also not be matchable with the 311 complaints.\n",
    "\n",
    "To solve the issues mentioned above let us:\n",
    "\n",
    "1. xxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
