{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Is the Relationship between Housing Characteristics and Complaints?\n",
    "\n",
    "The goal of this exercise is to find the answer to the Question 3 of the problem statement: \n",
    "\n",
    "> Does the Complaint Type that you identified in response to Question 1 have an obvious relationship with any particular characteristic or characteristic of the Houses?\n",
    "\n",
    "In this exercise, we shall use the 311 dataset in combination with the PLUTO data set. The latter shall be used for the most problematic borough that was identified as a part of answering the Question 2. \n",
    "Remember that, the answer to Question 1 (What Is the Top Complaint Type?) was: \n",
    "\n",
    "> The most often reported complaint is 'HEAT/HOT WATER'\n",
    "\n",
    "The answe to Question 2 (What Areas Should the Agency Focus On?) was:\n",
    "\n",
    "> The borough with the most 'HEAT/HOT WATER' complaints is 'BRONX'\n",
    "\n",
    "Therefore, in the remainder we shall analyze whether the 'HEAT/HOT WATER' comlaints reported in 'BRONX' have obvious relationship with any particular house characteristics.\n",
    "\n",
    "# The data sets\n",
    "The 311 dataset is already well known to us as it was used to answer Questions 1 & 2, therefore it does not require any special introduction. \n",
    "\n",
    "The PLUTO data set is new to us and it aggregates condominium unit tax lot informationto the billing lot.\n",
    "The initially recommended (by the course advisers) PLUTO data set fields to consider are:\n",
    "\n",
    "|    Field   |                  Description                     |\n",
    "|------------|--------------------------------------------------|\n",
    "| Address    | An address of the tax lot |\n",
    "| BldgArea   | The total gross area in square feet |\n",
    "| BldgDepth  | The buildingâ€™s depth, measured in feet |\n",
    "| BuiltFAR   | The build floor area ration |\n",
    "| CommFAR    | The maximum allowable commercial floor area ratio |\n",
    "| FacilFAR   | The maximum allowable community facility floor area ratio |\n",
    "| Lot        | The one to four-digit tax lot number |\n",
    "| LotArea    | Total area of the tax lot, in square feet |\n",
    "| LotDepth   | The tax lot's depth measured in feet |\n",
    "| NumBldgs   | The number of buildings on the tax lot |\n",
    "| NumFloors  | The number of full and partialstories starting from the ground floor, for the tallest building on the tax lot |\n",
    "| OfficeArea | An estimate of theexterior dimensions of the portion of the structure(s) allocated for office use |\n",
    "| ResArea    | An estimate of the exterior dimensions of the portion of the structure(s) allocated for residential use |\n",
    "| ResidFAR   | The maximum allowable residential floor area ratio |\n",
    "| RetailArea | An estimate of the exterior dimensions of the portion of the structure(s) allocated for retail use |\n",
    "| YearBuilt  | The year construction of the building was completed |\n",
    "| YearAlter1 | Is the year of the building's most recent alteration |\n",
    "| ZipCode    | A ZIP code that is valid for one of the addresses assigned to the tax lot |\n",
    "| XCoord     | The X coordinate of the XY coordinate pair which depicts the approximate location of the lot |\n",
    "| YCoord     | The Y coordinate of the XY coordinate pair which depicts the approximate location of the lot |\n",
    "\n",
    "Consider reading the [PLUTO Data Dictionary](https://www1.nyc.gov/assets/planning/download/pdf/data-maps/open-data/pluto_datadictionary.pdf?r=19v2) for more details. The data set archive consists of several CSV files, each devoted to a single borough:\n",
    "\n",
    "|   CSV file  |      Borough       |\n",
    "|-------------|--------------------|\n",
    "| QN_18v1.csv | QUEENS |\n",
    "| BK_18v1.csv | BROOKLYN |\n",
    "| SI_18v1.csv | STATEN ISLAND |\n",
    "| BX_18v1.csv | BRONX |\n",
    "| MN_18v1.csv | MANHATTAN |\n",
    "\n",
    "Since we are interested in borough *'BRONX'* we shall use the data from the corresponding *'BX_18v1.csv'* file.\n",
    "\n",
    "\n",
    "# Load the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading of the data can be done both from the IBM cloud storage and the locally present CSV files. The latter is decided upon the presence of the proper secure field values of the credentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ibm_boto3\n",
    "\n",
    "from botocore.client import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "SECURITY_DUMMY = '----------------'\n",
    "erm2_nwe9_creds = {\n",
    "    'IAM_SERVICE_ID'    : SECURITY_DUMMY,\n",
    "    'IBM_API_KEY_ID'    : SECURITY_DUMMY,\n",
    "    'ENDPOINT'          : 'https://s3.eu-geo.objectstorage.service.networklayer.com',\n",
    "    'IBM_AUTH_ENDPOINT' : 'https://iam.eu-gb.bluemix.net/oidc/token',\n",
    "    'BUCKET'            : SECURITY_DUMMY,\n",
    "    'FILE'              : 'erm2_nwe9.csv'\n",
    "}\n",
    "bx_18v1_creds = {\n",
    "    'IAM_SERVICE_ID'    : SECURITY_DUMMY,\n",
    "    'IBM_API_KEY_ID'    : SECURITY_DUMMY,\n",
    "    'ENDPOINT'          : 'https://s3.eu-geo.objectstorage.service.networklayer.com',\n",
    "    'IBM_AUTH_ENDPOINT' : 'https://iam.eu-gb.bluemix.net/oidc/token',\n",
    "    'BUCKET'            : SECURITY_DUMMY,\n",
    "    'FILE'              : 'BX_18v1.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows to get the data source for the credentials from the IBM cloud or local csv file \n",
    "def get_data_source(credentials) :\n",
    "    '''Creates a data source from the IBM cloud or local csv file according to the credentials'''\n",
    "    # Here we check if the credentials are present, if not try \n",
    "    # load the local file if they are then read from the cloud.\n",
    "    if credentials.get('IAM_SERVICE_ID') == SECURITY_DUMMY :\n",
    "        # This is the alternative to get the code run locally with a local csv file\n",
    "        body = 'data' + os.path.sep + credentials.get('FILE')\n",
    "    else :\n",
    "        client = ibm_boto3.client(\n",
    "            service_name = 's3',\n",
    "            ibm_api_key_id = credentials.get('IBM_API_KEY_ID'),\n",
    "            ibm_auth_endpoint = credentials.get('IBM_AUTH_ENDPOINT'),\n",
    "            config = Config(signature_version='oauth'),\n",
    "            endpoint_url = credentials.get('ENDPOINT'))\n",
    "\n",
    "        body = client.get_object(\n",
    "            Bucket = credentials.get('BUCKET'),\n",
    "            Key = credentials.get('FILE'))['Body']\n",
    "\n",
    "        # add missing __iter__ method, so pandas accepts body as file-like object\n",
    "        def __iter__(self): return 0\n",
    "        if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "    return body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, we shall subsequently load the 311 and PLUTO data sets. Along the way, we will select the necessary columns and check on (, and correct if needed,) the column data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The 311 data set\n",
    "Here we first load the 311 data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data source for the credentials\n",
    "dhp_ds = get_data_source(erm2_nwe9_creds)\n",
    "\n",
    "# Read the CSV file\n",
    "dhp_df = pd.read_csv(dhp_ds, parse_dates = ['created_date', 'closed_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we select the data related to the 'HEAT/HOT WATER' comlaints reported in 'BRONX'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all complaints: 6034470\n",
      "Number of 'HEAT/HOT WATER' complaints in 'BRONX': 609783\n"
     ]
    }
   ],
   "source": [
    "print('Number of all complaints:', dhp_df.shape[0])\n",
    "dhp_df = dhp_df[(dhp_df['complaint_type'] == 'HEAT/HOT WATER') & (dhp_df['borough'] == 'BRONX')]\n",
    "print('Number of \\'HEAT/HOT WATER\\' complaints in \\'BRONX\\':', dhp_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next lest us realize that the 311 data set will only be user to select the lots from the PLUTO data set which had 'HEAT/HOT WATER' complaints in 'BRONX'. Therefore, we shall only keep the relevant columns here, i.e. the property zip code and address. We shall also rename the columns to match those of PLUTO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>ZipCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>511 EAST  148 STREET</td>\n",
       "      <td>10455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1275 EDWARD L GRANT HIGHWAY</td>\n",
       "      <td>10452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>152 EAST  171 STREET</td>\n",
       "      <td>10452.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2523 UNIVERSITY AVENUE</td>\n",
       "      <td>10468.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3226 BRONXWOOD AVENUE</td>\n",
       "      <td>10469.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Address  ZipCode\n",
       "0          511 EAST  148 STREET  10455.0\n",
       "7   1275 EDWARD L GRANT HIGHWAY  10452.0\n",
       "12         152 EAST  171 STREET  10452.0\n",
       "16       2523 UNIVERSITY AVENUE  10468.0\n",
       "26        3226 BRONXWOOD AVENUE  10469.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhp_df = dhp_df[['incident_address', 'incident_zip']]\n",
    "dhp_df = dhp_df.rename({'incident_address':'Address', 'incident_zip':'ZipCode'}, axis=1)\n",
    "dhp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let us check on the column types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address     object\n",
       "ZipCode    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhp_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The types are in order as the address is a string and the zip code is a float.\n",
    "\n",
    "## The PLUTO data set\n",
    "Here we first load the PLUTO data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data source for the credentials\n",
    "bx_ds = get_data_source(bx_18v1_creds)\n",
    "\n",
    "# Read the CSV file\n",
    "bx_df = pd.read_csv(bx_ds, low_memory = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we select the recommended fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx_df = bx_df[['Address', 'BldgArea', 'BldgDepth', 'BuiltFAR',\n",
    "              'CommFAR', 'FacilFAR', 'Lot', 'LotArea', 'LotDepth',\n",
    "              'NumBldgs', 'NumFloors', 'OfficeArea', 'ResArea',\n",
    "              'ResidFAR', 'RetailArea', 'YearBuilt', 'YearAlter1',\n",
    "              'ZipCode', 'YCoord', 'XCoord']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further list the types of the columns to check if they are all in order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address        object\n",
       "BldgArea        int64\n",
       "BldgDepth     float64\n",
       "BuiltFAR      float64\n",
       "CommFAR       float64\n",
       "FacilFAR      float64\n",
       "Lot             int64\n",
       "LotArea         int64\n",
       "LotDepth      float64\n",
       "NumBldgs        int64\n",
       "NumFloors     float64\n",
       "OfficeArea      int64\n",
       "ResArea         int64\n",
       "ResidFAR      float64\n",
       "RetailArea      int64\n",
       "YearBuilt       int64\n",
       "YearAlter1      int64\n",
       "ZipCode       float64\n",
       "YCoord        float64\n",
       "XCoord        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data frame columns have proper numeric types, except for the Address one which is a string.\n",
    "\n",
    "# Data Exploration and Cleaning\n",
    "\n",
    "## The 311 data set\n",
    "\n",
    "We can now describe the 311 data set to get some insights in the remaining data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>ZipCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>609782</td>\n",
       "      <td>603797.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>22902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>3810 BAILEY AVENUE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>7115</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10460.695938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.493728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10451.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10456.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10467.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10803.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Address        ZipCode\n",
       "count               609782  603797.000000\n",
       "unique               22902            NaN\n",
       "top     3810 BAILEY AVENUE            NaN\n",
       "freq                  7115            NaN\n",
       "mean                   NaN   10460.695938\n",
       "std                    NaN       6.493728\n",
       "min                    NaN   10451.000000\n",
       "25%                    NaN   10456.000000\n",
       "50%                    NaN   10460.000000\n",
       "75%                    NaN   10467.000000\n",
       "max                    NaN   10803.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhp_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no much to see here as the provided statistics is mostly not informative. For the address, we can only tell that there are `609782` non Na/NaN  ones among which `22902` are unique and that the top complaints address is `3810 BAILEY AVENUE` with `7115` comlaints over all the years. For the zip codes the amount of useful information is even less, we can just use the number of non Na/NaN zip codes: `603797`. The latter indicates that there are about `609782 - 603797 = 5985` Na/NaN zip codes. Thereore, let us now explicitly check for the present Na/NaN values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing addresses is: 1 \n",
      "The number of missing zip codes is: 5986\n"
     ]
    }
   ],
   "source": [
    "missing = dhp_df.isna()\n",
    "print('The number of missing addresses is:', missing.Address.sum(),\n",
    "      '\\nThe number of missing zip codes is:', missing.ZipCode.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see there are missing values which we can not easily restore, so let us drop the corresponding rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of complaints including Na/NaN values: 609783\n",
      "The number of clean complaints: 603797\n"
     ]
    }
   ],
   "source": [
    "print('The number of complaints including Na/NaN values:', dhp_df.shape[0])\n",
    "dhp_df.dropna(inplace = True)\n",
    "print('The number of clean complaints:', dhp_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see, the amount of dropped data is marginal, i.e. it just about `100 - (603797 * 100 /609783) =  0.98`%.\n",
    "\n",
    "## The PLUTO data set\n",
    "We can now describe the PLUTO data set to get some insights in the selected data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>BldgArea</th>\n",
       "      <th>BldgDepth</th>\n",
       "      <th>BuiltFAR</th>\n",
       "      <th>CommFAR</th>\n",
       "      <th>FacilFAR</th>\n",
       "      <th>Lot</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>LotDepth</th>\n",
       "      <th>NumBldgs</th>\n",
       "      <th>NumFloors</th>\n",
       "      <th>OfficeArea</th>\n",
       "      <th>ResArea</th>\n",
       "      <th>ResidFAR</th>\n",
       "      <th>RetailArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearAlter1</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>YCoord</th>\n",
       "      <th>XCoord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>89785</td>\n",
       "      <td>8.985400e+04</td>\n",
       "      <td>89854.000000</td>\n",
       "      <td>89854.000000</td>\n",
       "      <td>89854.000000</td>\n",
       "      <td>89854.000000</td>\n",
       "      <td>89854.000000</td>\n",
       "      <td>8.985400e+04</td>\n",
       "      <td>89854.000000</td>\n",
       "      <td>89854.000000</td>\n",
       "      <td>89854.000000</td>\n",
       "      <td>8.985400e+04</td>\n",
       "      <td>8.985400e+04</td>\n",
       "      <td>89854.000000</td>\n",
       "      <td>89854.000000</td>\n",
       "      <td>89854.000000</td>\n",
       "      <td>89854.000000</td>\n",
       "      <td>89525.000000</td>\n",
       "      <td>86595.000000</td>\n",
       "      <td>8.659500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>87017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>SHORE DRIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8.113609e+03</td>\n",
       "      <td>48.229342</td>\n",
       "      <td>1.107134</td>\n",
       "      <td>0.130644</td>\n",
       "      <td>2.853723</td>\n",
       "      <td>111.493601</td>\n",
       "      <td>1.023904e+04</td>\n",
       "      <td>105.978085</td>\n",
       "      <td>1.184778</td>\n",
       "      <td>2.273265</td>\n",
       "      <td>5.057144e+02</td>\n",
       "      <td>5.720876e+03</td>\n",
       "      <td>1.674844</td>\n",
       "      <td>349.916910</td>\n",
       "      <td>1805.695150</td>\n",
       "      <td>176.591782</td>\n",
       "      <td>10464.280726</td>\n",
       "      <td>249975.676667</td>\n",
       "      <td>1.021686e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.520439e+04</td>\n",
       "      <td>31.333564</td>\n",
       "      <td>1.799155</td>\n",
       "      <td>0.574606</td>\n",
       "      <td>1.605805</td>\n",
       "      <td>467.387099</td>\n",
       "      <td>3.058252e+05</td>\n",
       "      <td>73.946506</td>\n",
       "      <td>1.929445</td>\n",
       "      <td>1.492908</td>\n",
       "      <td>1.196641e+04</td>\n",
       "      <td>5.660190e+04</td>\n",
       "      <td>1.309456</td>\n",
       "      <td>4911.023897</td>\n",
       "      <td>499.485278</td>\n",
       "      <td>567.142346</td>\n",
       "      <td>7.292127</td>\n",
       "      <td>9778.614120</td>\n",
       "      <td>8.599340e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10451.000000</td>\n",
       "      <td>227527.000000</td>\n",
       "      <td>1.002677e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.598000e+03</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.188000e+03</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.152000e+03</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1920.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10460.000000</td>\n",
       "      <td>241918.000000</td>\n",
       "      <td>1.014310e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.226000e+03</td>\n",
       "      <td>44.670000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>2.508000e+03</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.760000e+03</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1931.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10465.000000</td>\n",
       "      <td>248586.000000</td>\n",
       "      <td>1.023321e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.288000e+03</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>4.250000e+03</td>\n",
       "      <td>102.420000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.616000e+03</td>\n",
       "      <td>2.430000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1960.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10469.000000</td>\n",
       "      <td>258036.500000</td>\n",
       "      <td>1.027126e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.354011e+07</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>259.800000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9978.000000</td>\n",
       "      <td>7.425000e+07</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>1.311800e+06</td>\n",
       "      <td>1.321140e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>598908.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>11370.000000</td>\n",
       "      <td>272275.000000</td>\n",
       "      <td>1.047777e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Address      BldgArea     BldgDepth      BuiltFAR       CommFAR  \\\n",
       "count         89785  8.985400e+04  89854.000000  89854.000000  89854.000000   \n",
       "unique        87017           NaN           NaN           NaN           NaN   \n",
       "top     SHORE DRIVE           NaN           NaN           NaN           NaN   \n",
       "freq             42           NaN           NaN           NaN           NaN   \n",
       "mean            NaN  8.113609e+03     48.229342      1.107134      0.130644   \n",
       "std             NaN  6.520439e+04     31.333564      1.799155      0.574606   \n",
       "min             NaN  0.000000e+00      0.000000      0.000000      0.000000   \n",
       "25%             NaN  1.598000e+03     35.000000      0.550000      0.000000   \n",
       "50%             NaN  2.226000e+03     44.670000      0.860000      0.000000   \n",
       "75%             NaN  3.288000e+03     55.000000      1.250000      0.000000   \n",
       "max             NaN  1.354011e+07   1300.000000    259.800000      9.000000   \n",
       "\n",
       "            FacilFAR           Lot       LotArea      LotDepth      NumBldgs  \\\n",
       "count   89854.000000  89854.000000  8.985400e+04  89854.000000  89854.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        2.853723    111.493601  1.023904e+04    105.978085      1.184778   \n",
       "std         1.605805    467.387099  3.058252e+05     73.946506      1.929445   \n",
       "min         0.000000      1.000000  0.000000e+00      0.000000      0.000000   \n",
       "25%         2.000000     20.000000  2.188000e+03     95.000000      1.000000   \n",
       "50%         2.000000     41.000000  2.508000e+03    100.000000      1.000000   \n",
       "75%         4.800000     73.000000  4.250000e+03    102.420000      1.000000   \n",
       "max        10.000000   9978.000000  7.425000e+07   8000.000000    251.000000   \n",
       "\n",
       "           NumFloors    OfficeArea       ResArea      ResidFAR     RetailArea  \\\n",
       "count   89854.000000  8.985400e+04  8.985400e+04  89854.000000   89854.000000   \n",
       "unique           NaN           NaN           NaN           NaN            NaN   \n",
       "top              NaN           NaN           NaN           NaN            NaN   \n",
       "freq             NaN           NaN           NaN           NaN            NaN   \n",
       "mean        2.273265  5.057144e+02  5.720876e+03      1.674844     349.916910   \n",
       "std         1.492908  1.196641e+04  5.660190e+04      1.309456    4911.023897   \n",
       "min         0.000000  0.000000e+00  0.000000e+00      0.000000       0.000000   \n",
       "25%         2.000000  0.000000e+00  1.152000e+03      0.900000       0.000000   \n",
       "50%         2.000000  0.000000e+00  1.760000e+03      1.100000       0.000000   \n",
       "75%         3.000000  0.000000e+00  2.616000e+03      2.430000       0.000000   \n",
       "max        44.000000  1.311800e+06  1.321140e+07     10.000000  598908.000000   \n",
       "\n",
       "           YearBuilt    YearAlter1       ZipCode         YCoord        XCoord  \n",
       "count   89854.000000  89854.000000  89525.000000   86595.000000  8.659500e+04  \n",
       "unique           NaN           NaN           NaN            NaN           NaN  \n",
       "top              NaN           NaN           NaN            NaN           NaN  \n",
       "freq             NaN           NaN           NaN            NaN           NaN  \n",
       "mean     1805.695150    176.591782  10464.280726  249975.676667  1.021686e+06  \n",
       "std       499.485278    567.142346      7.292127    9778.614120  8.599340e+03  \n",
       "min         0.000000      0.000000  10451.000000  227527.000000  1.002677e+06  \n",
       "25%      1920.000000      0.000000  10460.000000  241918.000000  1.014310e+06  \n",
       "50%      1931.000000      0.000000  10465.000000  248586.000000  1.023321e+06  \n",
       "75%      1960.000000      0.000000  10469.000000  258036.500000  1.027126e+06  \n",
       "max      2017.000000   2017.000000  11370.000000  272275.000000  1.047777e+06  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
