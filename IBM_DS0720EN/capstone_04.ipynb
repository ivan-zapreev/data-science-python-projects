{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Complaint Types\n",
    "\n",
    "The goal of this exercise is to do Model Development and Validation to find the answer to the Question 4 of the problem statement:\n",
    "\n",
    "> Can a predictive model be built for future prediction of the possibility of complaints of the specific type that you identified in response to Question 1?\n",
    "\n",
    "This exercise will be based on the findings of the previous three exercises. Therefore, we shall use the 311 complaints and the PLUTO data sets to feature-engineer a 'HEAT/HOT WATER' complaints for tax lots dataset. The latter is to be used to build a predictive model to estimate the number of future complaints based on selected house characteristics (which we will also refer to as properties or features).\n",
    "\n",
    "We shall formalize the question at hand as follows:\n",
    "\n",
    "> Build a prediction model for the number of 'HEAT/HOT WATER' complaints per year for a house with a selectd set of characteristics.\n",
    "\n",
    "The rest of the work will be organized as follows, we shall:\n",
    "1. Load, clean and prepare the data sets\n",
    "   * In a similar way we did for answering Questions 1 to 3\n",
    "2. Join the '311 complaint' data set with the PLUTO one\n",
    "   * In a similar way we did for answering Questions 1 to 3\n",
    "3. Determine the models to be used\n",
    "   * This will influence the feature selection process\n",
    "4. Perform house feature selection\n",
    "   * This will be re-done as we used a different model for Question 3\n",
    "5. Perform model training\n",
    "   * Including parameter tuning and cross validation if any\n",
    "6. Evaluate and compare models\n",
    "7. Recommending the best performing model\n",
    "\n",
    "Please note that, the data sets will not be described as the latter has already been done when answering Questions 1 to 3. We shall only repeat that the PLUTO data set will initially be taked with the following set of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial set of PLUTO features to consider:\n",
      " ['Address', 'BldgArea', 'BldgDepth', 'BuiltFAR', 'CommFAR', 'FacilFAR', 'Lot', 'LotArea', 'LotDepth', 'NumBldgs', 'NumFloors', 'OfficeArea', 'ResArea', 'ResidFAR', 'RetailArea', 'YearBuilt', 'YearAlter1', 'ZipCode', 'YCoord', 'XCoord']\n"
     ]
    }
   ],
   "source": [
    "pluto_features = ['Address', 'BldgArea', 'BldgDepth', 'BuiltFAR',\n",
    "              'CommFAR', 'FacilFAR', 'Lot', 'LotArea', 'LotDepth',\n",
    "              'NumBldgs', 'NumFloors', 'OfficeArea', 'ResArea',\n",
    "              'ResidFAR', 'RetailArea', 'YearBuilt', 'YearAlter1',\n",
    "              'ZipCode', 'YCoord', 'XCoord']\n",
    "print('The initial set of PLUTO features to consider:\\n', pluto_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load, clean, prepare\n",
    "\n",
    "Loading of the data can be done both from the IBM cloud storage and the locally present CSV files. The latter is decided upon the presence of the proper secure field values of the credentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import seaborn\n",
    "import ibm_boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from botocore.client import Config\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "SECURITY_DUMMY = '----------------'\n",
    "erm2_nwe9_creds = {\n",
    "    'IAM_SERVICE_ID'    : SECURITY_DUMMY,\n",
    "    'IBM_API_KEY_ID'    : SECURITY_DUMMY,\n",
    "    'ENDPOINT'          : 'https://s3.eu-geo.objectstorage.service.networklayer.com',\n",
    "    'IBM_AUTH_ENDPOINT' : 'https://iam.eu-gb.bluemix.net/oidc/token',\n",
    "    'BUCKET'            : SECURITY_DUMMY,\n",
    "    'FILE'              : 'erm2_nwe9.csv'\n",
    "}\n",
    "bk_18v1_creds = {\n",
    "    'IAM_SERVICE_ID'    : SECURITY_DUMMY,\n",
    "    'IBM_API_KEY_ID'    : SECURITY_DUMMY,\n",
    "    'ENDPOINT'          : 'https://s3.eu-geo.objectstorage.service.networklayer.com',\n",
    "    'IBM_AUTH_ENDPOINT' : 'https://iam.eu-gb.bluemix.net/oidc/token',\n",
    "    'BUCKET'            : SECURITY_DUMMY,\n",
    "    'FILE'              : 'BK_18v1.csv'\n",
    "}\n",
    "bx_18v1_creds = {\n",
    "    'IAM_SERVICE_ID'    : SECURITY_DUMMY,\n",
    "    'IBM_API_KEY_ID'    : SECURITY_DUMMY,\n",
    "    'ENDPOINT'          : 'https://s3.eu-geo.objectstorage.service.networklayer.com',\n",
    "    'IBM_AUTH_ENDPOINT' : 'https://iam.eu-gb.bluemix.net/oidc/token',\n",
    "    'BUCKET'            : SECURITY_DUMMY,\n",
    "    'FILE'              : 'BX_18v1.csv'\n",
    "}\n",
    "mn_18v1_creds = {\n",
    "    'IAM_SERVICE_ID'    : SECURITY_DUMMY,\n",
    "    'IBM_API_KEY_ID'    : SECURITY_DUMMY,\n",
    "    'ENDPOINT'          : 'https://s3.eu-geo.objectstorage.service.networklayer.com',\n",
    "    'IBM_AUTH_ENDPOINT' : 'https://iam.eu-gb.bluemix.net/oidc/token',\n",
    "    'BUCKET'            : SECURITY_DUMMY,\n",
    "    'FILE'              : 'MN_18v1.csv'\n",
    "}\n",
    "qn_18v1_creds = {\n",
    "    'IAM_SERVICE_ID'    : SECURITY_DUMMY,\n",
    "    'IBM_API_KEY_ID'    : SECURITY_DUMMY,\n",
    "    'ENDPOINT'          : 'https://s3.eu-geo.objectstorage.service.networklayer.com',\n",
    "    'IBM_AUTH_ENDPOINT' : 'https://iam.eu-gb.bluemix.net/oidc/token',\n",
    "    'BUCKET'            : SECURITY_DUMMY,\n",
    "    'FILE'              : 'QN_18v1.csv'\n",
    "}\n",
    "si_18v1_creds = {\n",
    "    'IAM_SERVICE_ID'    : SECURITY_DUMMY,\n",
    "    'IBM_API_KEY_ID'    : SECURITY_DUMMY,\n",
    "    'ENDPOINT'          : 'https://s3.eu-geo.objectstorage.service.networklayer.com',\n",
    "    'IBM_AUTH_ENDPOINT' : 'https://iam.eu-gb.bluemix.net/oidc/token',\n",
    "    'BUCKET'            : SECURITY_DUMMY,\n",
    "    'FILE'              : 'SI_18v1.csv'\n",
    "}\n",
    "\n",
    "pluto_creds = [bk_18v1_creds, bx_18v1_creds, mn_18v1_creds, qn_18v1_creds, si_18v1_creds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows to get the data source for the credentials from the IBM cloud or local csv file \n",
    "def get_data_source(credentials) :\n",
    "    '''Creates a data source from the IBM cloud or local csv file according to the credentials'''\n",
    "    # Here we check if the credentials are present, if not try \n",
    "    # load the local file if they are then read from the cloud.\n",
    "    if credentials.get('IAM_SERVICE_ID') == SECURITY_DUMMY :\n",
    "        # This is the alternative to get the code run locally with a local csv file\n",
    "        body = 'data' + os.path.sep + credentials.get('FILE')\n",
    "    else :\n",
    "        client = ibm_boto3.client(\n",
    "            service_name = 's3',\n",
    "            ibm_api_key_id = credentials.get('IBM_API_KEY_ID'),\n",
    "            ibm_auth_endpoint = credentials.get('IBM_AUTH_ENDPOINT'),\n",
    "            config = Config(signature_version='oauth'),\n",
    "            endpoint_url = credentials.get('ENDPOINT'))\n",
    "\n",
    "        body = client.get_object(\n",
    "            Bucket = credentials.get('BUCKET'),\n",
    "            Key = credentials.get('FILE'))['Body']\n",
    "\n",
    "        # add missing __iter__ method, so pandas accepts body as file-like object\n",
    "        def __iter__(self): return 0\n",
    "        if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "    return body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, we shall subsequently load the 311 and PLUTO data sets. Along the way, we will select the necessary columns and check on (, and correct if needed,) the column data types.\n",
    "\n",
    "## 311 complaints\n",
    "\n",
    "Balow we load the data set, and then first select the required complaints along with the needed columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all complaints: 6034470\n"
     ]
    }
   ],
   "source": [
    "# Get the data source for the credentials\n",
    "dhp_ds = get_data_source(erm2_nwe9_creds)\n",
    "\n",
    "# Read the CSV file\n",
    "dhp_df = pd.read_csv(dhp_ds, parse_dates = ['created_date', 'closed_date'])\n",
    "print('Number of all complaints:', dhp_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'HEAT/HOT WATER' complaints is: 2159103\n"
     ]
    }
   ],
   "source": [
    "# Select the 'HEAT/HOT WATER' complaints\n",
    "dhp_df = dhp_df[(dhp_df['complaint_type'] == 'HEAT/HOT WATER')]\n",
    "print('Number of \\'HEAT/HOT WATER\\' complaints is:', dhp_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the columns that matter, and rename for convenience\n",
    "dhp_df = dhp_df[['created_date', 'incident_address', 'incident_zip']]\n",
    "dhp_df = dhp_df.rename({'incident_address':'Address', 'incident_zip':'ZipCode'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the address to upper case for uniformity\n",
    "dhp_df.Address = dhp_df.Address.map(str).map(str.upper)\n",
    "# Strip the address strings\n",
    "dhp_df.Address = dhp_df.Address.str.strip()\n",
    "# Replace sequence of white spaces with one\n",
    "dhp_df.Address = dhp_df.Address.str.replace('\\s+',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before dropping Na/NaN: 2159103 , after: 2140078\n"
     ]
    }
   ],
   "source": [
    "# Drop the Na/NaN valued rows\n",
    "init_size = dhp_df.shape[0]\n",
    "dhp_df.dropna(inplace = True)\n",
    "print('Number of rows before dropping Na/NaN:', init_size,', after:', dhp_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exract the year the complaint was created and then drop the *'created_date'* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhp_df['Year'] = dhp_df.created_date.dt.year\n",
    "dhp_df.drop(columns = ['created_date'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us summarize the Year statitics so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2140078\n",
       "mean        2014\n",
       "std            2\n",
       "min         2010\n",
       "25%         2012\n",
       "50%         2015\n",
       "75%         2017\n",
       "max         2020\n",
       "Name: Year, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_descr = dhp_df['Year'].describe().astype(int)\n",
    "year_descr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see the min/max years range is between `2010` and `2020` which means that there were no missing/wrong *'created_date'* values present.\n",
    "\n",
    "We will only need the average complaint counts per year for each given *'Address'*/*'ZipCode'* pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>Address</th>\n",
       "      <th>AvgCnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001.0</td>\n",
       "      <td>10 WEST 28 STREET</td>\n",
       "      <td>1.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001.0</td>\n",
       "      <td>100 WEST 26 STREET</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001.0</td>\n",
       "      <td>102 WEST 29 STREET</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001.0</td>\n",
       "      <td>103 WEST 27 STREET</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001.0</td>\n",
       "      <td>11 WEST 34 STREET</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ZipCode             Address    AvgCnt\n",
       "0  10001.0   10 WEST 28 STREET  1.454545\n",
       "1  10001.0  100 WEST 26 STREET  0.090909\n",
       "2  10001.0  102 WEST 29 STREET  0.727273\n",
       "3  10001.0  103 WEST 27 STREET  0.181818\n",
       "4  10001.0   11 WEST 34 STREET  0.090909"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by the zip code and address to count the complaints\n",
    "dhp_df = dhp_df.groupby(['ZipCode', 'Address']).size().to_frame()\n",
    "\n",
    "# Rename the counts column and then compute the average count for the min/max years range\n",
    "dhp_df.rename({0 : 'AvgCnt'}, axis = 1, inplace = True)\n",
    "dhp_df.AvgCnt = dhp_df.AvgCnt/(year_descr.loc['max'] - year_descr.loc['min'] + 1)\n",
    "\n",
    "# Re-set the indexes to turn the Address and ZipCode back into columns\n",
    "dhp_df.reset_index(level = 1, inplace = True)\n",
    "dhp_df.reset_index(level = 0, inplace = True)\n",
    "dhp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we check on the column types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZipCode    float64\n",
       "Address     object\n",
       "AvgCnt     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhp_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data types are in order: the address is a string and the zip code and average complaint count are floats.\n",
    "\n",
    "## PLUTO \n",
    "\n",
    "Let us load and combine all of the PLUTO csv files first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate to load all the PLUTO csv files and\n",
    "# re-combine them into a single data frame\n",
    "pluto_df = pd.DataFrame()\n",
    "for cred in pluto_creds :\n",
    "    # Get the data source for the credentials\n",
    "    ds = get_data_source(cred)\n",
    "    # Read and append the CSV file\n",
    "    pluto_df = pluto_df.append(pd.read_csv(ds, low_memory = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform initial pre-processing such as, selecting the right rows, dropping the Na/NaN valued rows, pre-processing the *'Address'* column values to match those of the '311 complaints' data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of PLUTO rows before: 859212 , after: 835242\n"
     ]
    }
   ],
   "source": [
    "num_pluto_rows = pluto_df.shape[0]\n",
    "\n",
    "# Select the recommended columns\n",
    "pluto_df = pluto_df[['Address', 'BldgArea', 'BldgDepth', 'BuiltFAR',\n",
    "              'CommFAR', 'FacilFAR', 'Lot', 'LotArea', 'LotDepth',\n",
    "              'NumBldgs', 'NumFloors', 'OfficeArea', 'ResArea',\n",
    "              'ResidFAR', 'RetailArea', 'YearBuilt', 'YearAlter1',\n",
    "              'ZipCode', 'YCoord', 'XCoord']]\n",
    "\n",
    "# Drop the Na/NaN valued rows\n",
    "pluto_df = pluto_df.dropna()\n",
    "\n",
    "# Convert the address to upper case for uniformity\n",
    "pluto_df.Address = pluto_df.Address.map(str).map(str.upper)\n",
    "# Strip the address strings\n",
    "pluto_df.Address = pluto_df.Address.str.strip()\n",
    "# Replace sequence of white spaces with one\n",
    "pluto_df.Address = pluto_df.Address.str.replace('\\s+',' ')\n",
    "\n",
    "print('The number of PLUTO rows before:', num_pluto_rows, ', after:', pluto_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know from aanswering Question 3, there are Address column values in the PLUTO data set that do not contain house numbers. As, before, let us drop entries those right away:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of PLUTO rows before: 835242 , after: 522280\n"
     ]
    }
   ],
   "source": [
    "num_pluto_rows = pluto_df.shape[0]\n",
    "\n",
    "# Create the pattern for selecting a proper address with one house\n",
    "# number followed by a white space and then an alpha numeric street\n",
    "# name which can contain multiple words separated by white spaces\n",
    "regex_pat = re.compile(r'^\\d+(\\s+\\w+)+')\n",
    "\n",
    "# Then we only select the addresses that have a house number in it\n",
    "pluto_df = pluto_df[pluto_df.Address.str.match(regex_pat)]\n",
    "\n",
    "print('The number of PLUTO rows before:', num_pluto_rows, ', after:', pluto_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the same as done for Question 3, we shall remove the entries with the duplicate *'Address'*/*'Zipcode'* pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of PLUTO rows before: 522280 , after: 520137\n"
     ]
    }
   ],
   "source": [
    "num_pluto_rows = pluto_df.shape[0]\n",
    "\n",
    "# First count the distinct ZipCode-Address groups\n",
    "occur_cnt = pluto_df.groupby(['ZipCode','Address']).size().to_frame()\n",
    "occur_cnt.reset_index(level=0, inplace = True)\n",
    "occur_cnt.reset_index(level=0, inplace = True)\n",
    "\n",
    "# Rename the counts column\n",
    "occur_cnt.rename(columns={0:'Count'}, inplace = True)\n",
    "\n",
    "# Join the data into the original table\n",
    "pluto_df_tmp = pd.merge(pluto_df, occur_cnt, left_on=['ZipCode','Address'], right_on=['ZipCode','Address'])\n",
    "\n",
    "# Only keep the Address - ZipCode pairs that occur once\n",
    "rows_index = pluto_df_tmp[pluto_df_tmp['Count'] > 1].index\n",
    "pluto_df = pluto_df_tmp.drop(rows_index, axis = 0)\n",
    "\n",
    "# Drop the counts columns is it will not be needed and remove the temporary object\n",
    "pluto_df = pluto_df.drop('Count', axis = 1)\n",
    "pluto_df_tmp = []\n",
    "\n",
    "print('The number of PLUTO rows before:', num_pluto_rows, ', after:', pluto_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us check on the column data types, as we see there is no unexpected types here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Address        object\n",
       "BldgArea        int64\n",
       "BldgDepth     float64\n",
       "BuiltFAR      float64\n",
       "CommFAR       float64\n",
       "FacilFAR      float64\n",
       "Lot             int64\n",
       "LotArea         int64\n",
       "LotDepth      float64\n",
       "NumBldgs        int64\n",
       "NumFloors     float64\n",
       "OfficeArea      int64\n",
       "ResArea         int64\n",
       "ResidFAR      float64\n",
       "RetailArea      int64\n",
       "YearBuilt       int64\n",
       "YearAlter1      int64\n",
       "ZipCode       float64\n",
       "YCoord        float64\n",
       "XCoord        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pluto_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Join data sets\n",
    "\n",
    "In this section we shall join the cleaned 311 and PLUTO data sets to form a single data frame, we shall do it by performing an inner joint on the 311 and PLUTO data frames. The goint will be done by *'Address'* and *'ZipCode'* columns. This way we will only get the complaints that are marched with the PLUTO tax lot. This approach solves the three yet unresolved issues with the PLUTO data set mentioned in the previous section by ignoring the complaints that could not be matched with the tax lots because of the missing house numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of 311 rows before: 126902 , after: 82937\n"
     ]
    }
   ],
   "source": [
    "num_311_rows = dhp_df.shape[0]\n",
    "\n",
    "dhp_pluto_df = pd.merge(dhp_df, pluto_df, how='inner', left_on=['ZipCode','Address'], right_on=['ZipCode','Address'])\n",
    "\n",
    "print('The number of 311 rows before:', num_311_rows, ', after:', dhp_pluto_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see the inner joint has reduced our data quite significantly, i.e. by about `100 - (82937 * 100) / 126902 = 34.64`%. However, this is the price we have to pay unless we do a more thorough pre-porocessing of the PLUTO data set. \n",
    "\n",
    "Please note that, the number of house properties (features) that is selected is currently rather large:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of selected features is: 17\n"
     ]
    }
   ],
   "source": [
    "NUM_FEATURES = (dhp_pluto_df.shape[1] - len(['Lot', 'Address', 'ZipCode', 'AvgCnt']))\n",
    "print('The number of selected features is:', NUM_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not consider *'Lot'*, *'Address'*, *'ZipCode'*, and *'AvgCnt'* as the former two were used to join the 311 and PLUTO data sets and are not directly related to house properties. The latter is the target variable, i.e. the one that shall depend on the house properties.\n",
    "\n",
    "It does not seem that the *'Lot'*, *'Address'* and *'ZipCode'* columns will be needed so let us drop them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AvgCnt</th>\n",
       "      <th>BldgArea</th>\n",
       "      <th>BldgDepth</th>\n",
       "      <th>BuiltFAR</th>\n",
       "      <th>CommFAR</th>\n",
       "      <th>FacilFAR</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>LotDepth</th>\n",
       "      <th>NumBldgs</th>\n",
       "      <th>NumFloors</th>\n",
       "      <th>OfficeArea</th>\n",
       "      <th>ResArea</th>\n",
       "      <th>ResidFAR</th>\n",
       "      <th>RetailArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearAlter1</th>\n",
       "      <th>YCoord</th>\n",
       "      <th>XCoord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.454545</td>\n",
       "      <td>9763</td>\n",
       "      <td>98.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2469</td>\n",
       "      <td>98.75</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4888</td>\n",
       "      <td>1930</td>\n",
       "      <td>1979</td>\n",
       "      <td>210644.0</td>\n",
       "      <td>987501.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>8970</td>\n",
       "      <td>82.0</td>\n",
       "      <td>4.16</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2156</td>\n",
       "      <td>98.75</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1790</td>\n",
       "      <td>1920</td>\n",
       "      <td>1989</td>\n",
       "      <td>211297.0</td>\n",
       "      <td>986855.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>4796</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.88</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1668</td>\n",
       "      <td>83.42</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3276</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1520</td>\n",
       "      <td>1920</td>\n",
       "      <td>1989</td>\n",
       "      <td>210983.0</td>\n",
       "      <td>986664.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.090909</td>\n",
       "      <td>17153</td>\n",
       "      <td>120.0</td>\n",
       "      <td>5.42</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3162</td>\n",
       "      <td>126.50</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1877</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7765</td>\n",
       "      <td>1920</td>\n",
       "      <td>0</td>\n",
       "      <td>212224.0</td>\n",
       "      <td>988263.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>20422</td>\n",
       "      <td>96.0</td>\n",
       "      <td>4.83</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4229</td>\n",
       "      <td>98.75</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4834</td>\n",
       "      <td>1920</td>\n",
       "      <td>2005</td>\n",
       "      <td>211262.0</td>\n",
       "      <td>986709.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AvgCnt  BldgArea  BldgDepth  BuiltFAR  CommFAR  FacilFAR  LotArea  \\\n",
       "0  1.454545      9763       98.0      3.95     10.0      10.0     2469   \n",
       "1  0.727273      8970       82.0      4.16     10.0      10.0     2156   \n",
       "2  0.181818      4796       76.0      2.88     10.0      10.0     1668   \n",
       "3  0.090909     17153      120.0      5.42     15.0      15.0     3162   \n",
       "4  0.545455     20422       96.0      4.83     10.0      10.0     4229   \n",
       "\n",
       "   LotDepth  NumBldgs  NumFloors  OfficeArea  ResArea  ResidFAR  RetailArea  \\\n",
       "0     98.75         1        5.0           0     4875       0.0        4888   \n",
       "1     98.75         1        5.0           0        0      10.0        1790   \n",
       "2     83.42         1        4.0           0     3276      10.0        1520   \n",
       "3    126.50         1        6.0        1877        0      10.0        7765   \n",
       "4     98.75         2        7.0           0    12866       0.0        4834   \n",
       "\n",
       "   YearBuilt  YearAlter1    YCoord    XCoord  \n",
       "0       1930        1979  210644.0  987501.0  \n",
       "1       1920        1989  211297.0  986855.0  \n",
       "2       1920        1989  210983.0  986664.0  \n",
       "3       1920           0  212224.0  988263.0  \n",
       "4       1920        2005  211262.0  986709.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dhp_pluto_df.drop(columns = ['Lot', 'Address', 'ZipCode'], inplace = True)\n",
    "display(dhp_pluto_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us double-check that there are no Na/NaN values present in the resulting joint data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AvgCnt</th>\n",
       "      <th>BldgArea</th>\n",
       "      <th>BldgDepth</th>\n",
       "      <th>BuiltFAR</th>\n",
       "      <th>CommFAR</th>\n",
       "      <th>FacilFAR</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>LotDepth</th>\n",
       "      <th>NumBldgs</th>\n",
       "      <th>NumFloors</th>\n",
       "      <th>OfficeArea</th>\n",
       "      <th>ResArea</th>\n",
       "      <th>ResidFAR</th>\n",
       "      <th>RetailArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearAlter1</th>\n",
       "      <th>YCoord</th>\n",
       "      <th>XCoord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "      <td>82937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AvgCnt BldgArea BldgDepth BuiltFAR CommFAR FacilFAR LotArea LotDepth  \\\n",
       "count   82937    82937     82937    82937   82937    82937   82937    82937   \n",
       "unique      1        1         1        1       1        1       1        1   \n",
       "top     False    False     False    False   False    False   False    False   \n",
       "freq    82937    82937     82937    82937   82937    82937   82937    82937   \n",
       "\n",
       "       NumBldgs NumFloors OfficeArea ResArea ResidFAR RetailArea YearBuilt  \\\n",
       "count     82937     82937      82937   82937    82937      82937     82937   \n",
       "unique        1         1          1       1        1          1         1   \n",
       "top       False     False      False   False    False      False     False   \n",
       "freq      82937     82937      82937   82937    82937      82937     82937   \n",
       "\n",
       "       YearAlter1 YCoord XCoord  \n",
       "count       82937  82937  82937  \n",
       "unique          1      1      1  \n",
       "top         False  False  False  \n",
       "freq        82937  82937  82937  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhp_pluto_df.isna().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the table above there are no Na/NaN values present so we can proceed with building models to predict the number of 'HEAT/HOT WATER' comlaints per year based on house properties.\n",
    "\n",
    "# 3. Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Univariate Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Feature correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Final selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Evaluation summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
